{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b741774-aa7a-454a-b67a-4dba50430ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ensemble model loaded successfully\n",
      "✓ OpenAI client initialized successfully\n",
      "✓ Model loaded successfully\n",
      "Starting Flask server with LLM integration...\n",
      "Available endpoints:\n",
      "  GET  /health      - Check server status\n",
      "  GET  /features    - Get required features\n",
      "  GET  /sample      - Get sample input\n",
      "  GET  /llm_status  - Check LLM configuration\n",
      "  POST /predict     - Make prediction with AI analysis\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5005\n",
      " * Running on http://172.16.128.14:5005\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [31/Oct/2025 14:29:08] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM generation failed: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# flask_app_with_llm.py - Flask API Server with LLM Explanations\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import openai\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Define the ensemble predictor class FIRST (same as in training)\n",
    "class EnsemblePredictor:\n",
    "    def __init__(self, nn_model, rf_model, ridge_model, scaler, feature_cols, weights=[0.3, 0.4, 0.3]):\n",
    "        self.nn_model = nn_model\n",
    "        self.rf_model = rf_model\n",
    "        self.ridge_model = ridge_model\n",
    "        self.scaler = scaler\n",
    "        self.feature_cols = feature_cols\n",
    "        self.weights = weights\n",
    "        \n",
    "    def predict(self, input_df):\n",
    "        # Ensure columns present\n",
    "        missing = [c for c in self.feature_cols if c not in input_df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required features: {missing}\")\n",
    "        \n",
    "        # Prepare features\n",
    "        X_in = input_df[self.feature_cols].values\n",
    "        X_in_scaled = self.scaler.transform(X_in)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        nn_pred = self.nn_model.predict(X_in_scaled)\n",
    "        rf_pred = self.rf_model.predict(X_in_scaled)\n",
    "        ridge_pred = self.ridge_model.predict(X_in_scaled)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        ensemble_pred = (self.weights[0] * nn_pred + \n",
    "                        self.weights[1] * rf_pred + \n",
    "                        self.weights[2] * ridge_pred)\n",
    "        \n",
    "        # Clip to reasonable credit score range\n",
    "        ensemble_pred = np.clip(ensemble_pred, 300.0, 850.0)\n",
    "        return ensemble_pred\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configuration\n",
    "MODEL_DIR = r\"/Users/shwetank/Desktop/kannu\"\n",
    "ENSEMBLE_MODEL_PATH = os.path.join(MODEL_DIR, \"ensemble_predictor.pkl\")\n",
    "FEATURES_META_PATH = os.path.join(MODEL_DIR, \"feature_cols.json\")\n",
    "\n",
    "# LLM Configuration\n",
    "OPENAI_API_KEY = \"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\"  # Replace with your actual API key\n",
    "USE_LLM = True  # Set to False to disable LLM and use rule-based only\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load model with detailed error handling\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(ENSEMBLE_MODEL_PATH):\n",
    "            return None, f\"Model file not found at: {ENSEMBLE_MODEL_PATH}\"\n",
    "        \n",
    "        ensemble_predictor = joblib.load(ENSEMBLE_MODEL_PATH)\n",
    "        \n",
    "        # Verify the model has required methods\n",
    "        if not hasattr(ensemble_predictor, 'predict'):\n",
    "            return None, \"Loaded model doesn't have predict method\"\n",
    "            \n",
    "        print(\"✓ Ensemble model loaded successfully\")\n",
    "        return ensemble_predictor, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"Error loading model: {str(e)}\"\n",
    "\n",
    "def load_feature_cols():\n",
    "    \"\"\"Load feature columns\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(FEATURES_META_PATH):\n",
    "            return None, f\"Feature file not found at: {FEATURES_META_PATH}\"\n",
    "        \n",
    "        with open(FEATURES_META_PATH, 'r') as f:\n",
    "            feature_cols = json.load(f)\n",
    "        return feature_cols, None\n",
    "    except Exception as e:\n",
    "        return None, f\"Error loading features: {str(e)}\"\n",
    "\n",
    "def initialize_openai():\n",
    "    \"\"\"Initialize OpenAI client\"\"\"\n",
    "    try:\n",
    "        if OPENAI_API_KEY and OPENAI_API_KEY != \"your-openai-api-key-here\":\n",
    "            openai.api_key = OPENAI_API_KEY\n",
    "            # Test the connection with a simple request\n",
    "            print(\"✓ OpenAI client initialized successfully\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"⚠️  OpenAI API key not set. LLM features disabled.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Failed to initialize OpenAI: {e}\")\n",
    "        return False\n",
    "\n",
    "def generate_llm_explanation(pred_score: float, features: Dict[str, Any], rule_based_explanation: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate detailed explanation using OpenAI GPT\n",
    "    \"\"\"\n",
    "    if not USE_LLM or not openai.api_key:\n",
    "        return rule_based_explanation\n",
    "    \n",
    "    try:\n",
    "        # Extract key financial metrics\n",
    "        income = features.get('INCOME', 0)\n",
    "        savings = features.get('SAVINGS', 0)\n",
    "        debt = features.get('DEBT', 0)\n",
    "        debt_to_income = features.get('R_DEBT_INCOME', 0)\n",
    "        savings_to_income = features.get('R_SAVINGS_INCOME', 0)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        total_expenditure = features.get('T_EXPENDITURE_12', 0)\n",
    "        savings_rate = (savings / income * 100) if income > 0 else 0\n",
    "        debt_utilization = (debt / (income * 10)) * 100 if income > 0 else 0  # Rough estimate\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        As a financial advisor, analyze this credit profile and provide a detailed, personalized explanation:\n",
    "\n",
    "        CREDIT SCORE: {pred_score:.0f}\n",
    "        \n",
    "        FINANCIAL SNAPSHOT:\n",
    "        - Annual Income: ${income:,.0f}\n",
    "        - Savings: ${savings:,.0f}\n",
    "        - Total Debt: ${debt:,.0f}\n",
    "        - Debt-to-Income Ratio: {debt_to_income:.1f}x\n",
    "        - Savings-to-Income Ratio: {savings_to_income:.1f}x\n",
    "        - Annual Expenditure: ${total_expenditure:,.0f}\n",
    "        - Savings Rate: {savings_rate:.1f}%\n",
    "        - Debt Utilization: {debt_utilization:.1f}%\n",
    "\n",
    "        SPENDING PATTERNS:\n",
    "        - Housing: ${features.get('T_HOUSING_12', 0):,.0f}\n",
    "        - Groceries: ${features.get('T_GROCERIES_12', 0):,.0f}\n",
    "        - Entertainment: ${features.get('T_ENTERTAINMENT_12', 0):,.0f}\n",
    "        - Travel: ${features.get('T_TRAVEL_12', 0):,.0f}\n",
    "        - Utilities: ${features.get('T_UTILITIES_12', 0):,.0f}\n",
    "\n",
    "        FINANCIAL BEHAVIORS:\n",
    "        - Gambling Activity: {['None', 'Low', 'High'][features.get('CAT_GAMBLING', 0)]}\n",
    "        - Has Credit Card: {'Yes' if features.get('CAT_CREDIT_CARD', 0) else 'No'}\n",
    "        - Has Mortgage: {'Yes' if features.get('CAT_MORTGAGE', 0) else 'No'}\n",
    "        - Has Savings Account: {'Yes' if features.get('CAT_SAVINGS_ACCOUNT', 0) else 'No'}\n",
    "\n",
    "        Please provide:\n",
    "        1. Credit score interpretation and what it means for loan eligibility\n",
    "        2. Analysis of financial strengths and weaknesses\n",
    "        3. Specific, actionable recommendations to improve the credit score\n",
    "        4. Timeline expectations for improvement\n",
    "        5. Any red flags or areas of concern\n",
    "\n",
    "        Keep the response professional, empathetic, and focused on practical advice.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a knowledgeable and empathetic financial advisor specializing in credit analysis and personal finance.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=800,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"LLM generation failed: {e}\")\n",
    "        return f\"{rule_based_explanation}\\n\\n[Note: Advanced AI analysis temporarily unavailable]\"\n",
    "\n",
    "def explain_rule_based(pred_score, features_dict):\n",
    "    \"\"\"Enhanced rule-based explanation\"\"\"\n",
    "    lines = []\n",
    "    \n",
    "    # Interpret score\n",
    "    if pred_score >= 780:\n",
    "        lines.append(f\"Credit Score: {pred_score:.0f} — EXCELLENT\")\n",
    "        lines.append(\"You have exceptional credit! You'll qualify for the best rates and terms.\")\n",
    "    elif pred_score >= 720:\n",
    "        lines.append(f\"Credit Score: {pred_score:.0f} — VERY GOOD\")\n",
    "        lines.append(\"Strong credit profile with access to favorable lending terms.\")\n",
    "    elif pred_score >= 680:\n",
    "        lines.append(f\"Credit Score: {pred_score:.0f} — GOOD\")\n",
    "        lines.append(\"Solid credit standing with good approval chances.\")\n",
    "    elif pred_score >= 620:\n",
    "        lines.append(f\"Credit Score: {pred_score:.0f} — FAIR\")\n",
    "        lines.append(\"Average credit score with room for improvement.\")\n",
    "    else:\n",
    "        lines.append(f\"Credit Score: {pred_score:.0f} — POOR\")\n",
    "        lines.append(\"Credit needs significant improvement for better financial opportunities.\")\n",
    "    \n",
    "    # Key financial metrics analysis\n",
    "    income = features_dict.get('INCOME', 0)\n",
    "    debt = features_dict.get('DEBT', 0)\n",
    "    savings = features_dict.get('SAVINGS', 0)\n",
    "    debt_to_income = features_dict.get('R_DEBT_INCOME', 0)\n",
    "    \n",
    "    lines.append(\"\\nFINANCIAL ANALYSIS:\")\n",
    "    \n",
    "    if debt_to_income > 8:\n",
    "        lines.append(\"⚠️  High debt burden - consider debt reduction strategies\")\n",
    "    elif debt_to_income > 5:\n",
    "        lines.append(\"📊 Moderate debt level - manageable but watch spending\")\n",
    "    else:\n",
    "        lines.append(\"✅ Healthy debt-to-income ratio\")\n",
    "    \n",
    "    if savings > income * 0.3:\n",
    "        lines.append(\"💰 Strong savings position\")\n",
    "    elif savings > income * 0.1:\n",
    "        lines.append(\"📈 Adequate emergency fund\")\n",
    "    else:\n",
    "        lines.append(\"💡 Consider building larger savings buffer\")\n",
    "    \n",
    "    # Spending analysis\n",
    "    housing_ratio = features_dict.get('R_HOUSING_INCOME', 0)\n",
    "    if housing_ratio > 0.3:\n",
    "        lines.append(\"🏠 Housing costs are high relative to income\")\n",
    "    \n",
    "    # Recommendations\n",
    "    lines.append(\"\\nRECOMMENDATIONS:\")\n",
    "    if pred_score < 680:\n",
    "        lines.append(\"1. Reduce credit card balances below 30% of limits\")\n",
    "        lines.append(\"2. Ensure all bills are paid on time\")\n",
    "        lines.append(\"3. Avoid new credit applications for 6-12 months\")\n",
    "    \n",
    "    if debt_to_income > 5:\n",
    "        lines.append(\"4. Focus on paying down high-interest debt first\")\n",
    "    \n",
    "    if features_dict.get('CAT_GAMBLING', 0) == 2:  # High gambling\n",
    "        lines.append(\"5. Consider reducing discretionary spending on entertainment\")\n",
    "    \n",
    "    lines.append(\"6. Monitor credit report regularly for errors\")\n",
    "    lines.append(\"7. Maintain diverse credit mix (installment + revolving)\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Load model on startup\n",
    "ensemble_predictor, model_error = load_model()\n",
    "feature_cols, feature_error = load_feature_cols()\n",
    "openai_initialized = initialize_openai()\n",
    "\n",
    "if model_error:\n",
    "    print(f\"⚠️  Model loading failed: {model_error}\")\n",
    "    print(\"💡 Run train_final.py to create models\")\n",
    "else:\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "\n",
    "if feature_error:\n",
    "    print(f\"⚠️  Feature loading failed: {feature_error}\")\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        if not ensemble_predictor:\n",
    "            return jsonify({\n",
    "                \"error\": \"Model not loaded\", \n",
    "                \"details\": model_error,\n",
    "                \"solution\": \"Run train_final.py to create models first\"\n",
    "            }), 500\n",
    "        \n",
    "        # Get JSON data from request\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data:\n",
    "            return jsonify({\"error\": \"No data provided\"}), 400\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        input_df = pd.DataFrame([data])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = ensemble_predictor.predict(input_df)[0]\n",
    "        \n",
    "        # Generate rule-based explanation\n",
    "        rule_based_explanation = explain_rule_based(prediction, data)\n",
    "        \n",
    "        # Generate LLM explanation (if enabled)\n",
    "        llm_explanation = generate_llm_explanation(prediction, data, rule_based_explanation)\n",
    "        \n",
    "        response_data = {\n",
    "            \"predicted_credit_score\": float(prediction),\n",
    "            \"credit_rating\": get_credit_rating(prediction),\n",
    "            \"rule_based_explanation\": rule_based_explanation,\n",
    "            \"ai_analysis\": llm_explanation,\n",
    "            \"llm_enabled\": USE_LLM and openai_initialized,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        return jsonify(response_data)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "def get_credit_rating(score: float) -> str:\n",
    "    \"\"\"Convert numeric score to credit rating\"\"\"\n",
    "    if score >= 780:\n",
    "        return \"Excellent\"\n",
    "    elif score >= 720:\n",
    "        return \"Very Good\"\n",
    "    elif score >= 680:\n",
    "        return \"Good\"\n",
    "    elif score >= 620:\n",
    "        return \"Fair\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\n",
    "        \"status\": \"healthy\" if ensemble_predictor else \"unhealthy\",\n",
    "        \"model_loaded\": ensemble_predictor is not None,\n",
    "        \"model_error\": model_error if not ensemble_predictor else None,\n",
    "        \"features_loaded\": feature_cols is not None,\n",
    "        \"llm_enabled\": USE_LLM and openai_initialized,\n",
    "        \"openai_configured\": openai_initialized\n",
    "    })\n",
    "\n",
    "@app.route('/features', methods=['GET'])\n",
    "def features():\n",
    "    if feature_cols:\n",
    "        return jsonify({\n",
    "            \"required_features\": feature_cols,\n",
    "            \"total_features\": len(feature_cols)\n",
    "        })\n",
    "    else:\n",
    "        return jsonify({\n",
    "            \"error\": \"Features not loaded\",\n",
    "            \"details\": feature_error\n",
    "        }), 500\n",
    "\n",
    "@app.route('/sample', methods=['GET'])\n",
    "def sample():\n",
    "    \"\"\"Return sample input data structure\"\"\"\n",
    "    sample_data = {\n",
    "        \"INCOME\": 50000,\n",
    "        \"SAVINGS\": 25000,\n",
    "        \"DEBT\": 150000,\n",
    "        \"R_SAVINGS_INCOME\": 0.5,\n",
    "        \"R_DEBT_INCOME\": 3.0,\n",
    "        \"R_DEBT_SAVINGS\": 6.0,\n",
    "        \"T_CLOTHING_12\": 1200,\n",
    "        \"T_CLOTHING_6\": 600,\n",
    "        \"R_CLOTHING\": 0.5,\n",
    "        \"R_CLOTHING_INCOME\": 0.024,\n",
    "        \"CAT_GAMBLING\": 1\n",
    "    }\n",
    "    return jsonify({\"sample_input\": sample_data})\n",
    "\n",
    "@app.route('/llm_status', methods=['GET'])\n",
    "def llm_status():\n",
    "    \"\"\"Check LLM configuration status\"\"\"\n",
    "    return jsonify({\n",
    "        \"llm_enabled\": USE_LLM,\n",
    "        \"openai_configured\": openai_initialized,\n",
    "        \"api_key_set\": bool(OPENAI_API_KEY and OPENAI_API_KEY != \"your-openai-api-key-here\")\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting Flask server with LLM integration...\")\n",
    "    print(\"Available endpoints:\")\n",
    "    print(\"  GET  /health      - Check server status\")\n",
    "    print(\"  GET  /features    - Get required features\")\n",
    "    print(\"  GET  /sample      - Get sample input\")\n",
    "    print(\"  GET  /llm_status  - Check LLM configuration\")\n",
    "    print(\"  POST /predict     - Make prediction with AI analysis\")\n",
    "    \n",
    "    if not ensemble_predictor:\n",
    "        print(\"\\n⚠️  WARNING: Model not loaded!\")\n",
    "        print(\"💡 Run: python train_final.py\")\n",
    "    \n",
    "    if not openai_initialized:\n",
    "        print(\"\\n⚠️  LLM features disabled!\")\n",
    "        print(\"💡 Set OPENAI_API_KEY in the script to enable AI explanations\")\n",
    "    \n",
    "    app.run(host='0.0.0.0', port=5005, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e8e2d-ff17-4f49-a159-5cb44c1731a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kill -9 <PID>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f578f-d6af-40ea-9994-00d5659a9167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kannubaby]",
   "language": "python",
   "name": "conda-env-kannubaby-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
